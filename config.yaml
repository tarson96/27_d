# ─────────────────────── performance tables ──────────────────────────────
gpu_performance:
  GPU_TFLOPS_FP16:
    NVIDIA B200: 1205
    NVIDIA H200: 610
    NVIDIA H100 80GB HBM3: 570
    NVIDIA H100 PCIe: 330
    NVIDIA H100 NVL: 218
    NVIDIA A100-SXM4-80GB: 238.8
    NVIDIA A100 80GB PCIe: 197
    NVIDIA A100-SXM4-40GB: 257
    NVIDIA GeForce RTX 5090: 220.0
    NVIDIA L40S: 171
    NVIDIA L40: 116
    NVIDIA RTX 6000 Ada Generation: 112
    NVIDIA RTX A6000: 48.5
    NVIDIA RTX A5000: 60.0
    NVIDIA RTX A4500: 44.0
    NVIDIA RTX 4000 Ada Generation: 70
    NVIDIA A40: 40.0
    NVIDIA GeForce RTX 4090: 157
    NVIDIA GeForce RTX 3090: 66.4
    NVIDIA L4: 51
  GPU_TFLOPS_FP32:
    NVIDIA B200: 67.2
    NVIDIA GeForce RTX 5090: 65.0
    NVIDIA H200: 49.6
    NVIDIA H100 80GB HBM3: 49.0
    NVIDIA H100 PCIe: 37.2
    NVIDIA H100 NVL: 32.0
    NVIDIA A100-SXM4-80GB: 18.2
    NVIDIA A100 80GB PCIe: 16.9
    NVIDIA A100-SXM4-40GB: 18.2
    NVIDIA L40S: 35.5
    NVIDIA L40: 27.0
    NVIDIA RTX 6000 Ada Generation: 26.0
    NVIDIA RTX A6000: 21.28
    NVIDIA GeForce RTX 3090: 21.7
    NVIDIA RTX A5000: 15.8
    NVIDIA RTX A4500: 14.3
    NVIDIA RTX 4000 Ada Generation: 14.6
    NVIDIA A40: 22.8
    NVIDIA GeForce RTX 4090: 48.5
    NVIDIA L4: 9
  GPU_AVRAM:
    NVIDIA B200: 68.72
    NVIDIA H200: 68.72
    NVIDIA H100 80GB HBM3: 34.36
    NVIDIA H100 PCIe: 34.36
    NVIDIA H100 NVL: 34.36
    NVIDIA A100-SXM4-80GB: 34.36
    NVIDIA A100 80GB PCIe: 34.36
    NVIDIA A100-SXM4-40GB: 17.18
    NVIDIA GeForce RTX 5090: 17.18
    NVIDIA L40S: 17.18
    NVIDIA L40: 17.18
    NVIDIA RTX 6000 Ada Generation: 17.18
    NVIDIA RTX A6000: 17.18
    NVIDIA RTX A5000: 8.59
    NVIDIA RTX A4500: 8.59
    NVIDIA RTX 4000 Ada Generation: 8.59
    NVIDIA A40: 17.18
    NVIDIA GeForce RTX 4090: 8.59
    NVIDIA GeForce RTX 3090: 8.59
    NVIDIA L4: 8.59

  gpu_tolerance_pairs:
    NVIDIA L40s: NVIDIA L40S
    NVIDIA RTX 4090: NVIDIA GeForce RTX 4090
    NVIDIA H100": NVIDIA H100 PCIe
    NVIDIA H100 NVL: NVIDIA H100 PCIe
    NVIDIA H100 PCIe: NVIDIA H100 NVL
    NVIDIA L40: NVIDIA RTX 6000 Ada Generation
    NVIDIA RTX 6000 Ada Generation: NVIDIA L40
    NVIDIA RTX 4000 Ada Generation: NVIDIA RTX A5000
    NVIDIA RTX A5000: NVIDIA RTX 4000 Ada Generation
    NVIDIA A100 80GB PCIe: NVIDIA A100-SXM4-80GB
    NVIDIA A100-SXM4-80GB: NVIDIA A100 80GB PCIe
    NVIDIA H100 80GB HBM3: NVIDIA H100
    NVIDIA H100: NVIDIA H100 80GB HBM3
    NVIDIA A40: NVIDIA RTX A6000
    NVIDIA RTX A6000: NVIDIA A40

  gpu_scores:
    NVIDIA B200: 4.80
    NVIDIA H200: 3.99
    NVIDIA H100 NVL: 3.15
    NVIDIA H100 80GB HBM3: 2.99
    NVIDIA H100 PCIe: 2.79
    NVIDIA A100-SXM4-80GB: 1.89
    NVIDIA A100 80GB PCIe: 1.64
    NVIDIA L40S: 1.03
    NVIDIA GeForce RTX 5090: 0.92
    NVIDIA RTX 6000 Ada Generation: 0.88
    NVIDIA L40: 0.99
    NVIDIA RTX A6000: 0.76
    NVIDIA RTX 4090: 0.69
    NVIDIA A40: 0.39
    NVIDIA GeForce RTX 3090: 0.43
    NVIDIA L4: 0.43
    NVIDIA RTX A5000: 0.26
    NVIDIA RTX A4500: 0.34

# ───────────────── quadratic timing models (+ tolerance) ─────────────────
gpu_time_models:
  NVIDIA GeForce RTX 4090:            {a0: 5.58, a1: 2.31, a2: -0.14, tol: 1.30}
  NVIDIA GeForce RTX 5090:            {a0: 6.16, a1: 3.24, a2:  -0.14, tol: 1.30}
  NVIDIA A100 80GB PCIe:              {a0: 18.74, a1: 12.53, a2: -0.78, tol: 1.30}
  NVIDIA L4:                          {a0: 13.89, a1: 1.09, a2:  0.00, tol: 1.30}
  NVIDIA A40:                         {a0: 15.12, a1: 2.08, a2: -0.11, tol: 1.30}
  NVIDIA L40:                         {a0: 11.60, a1: 4.96, a2: -0.31, tol: 1.30}
  NVIDIA RTX A4500:                   {a0: 10.86, a1: 0.33, a2:  0.00, tol: 1.30}
  NVIDIA RTX A5000:                   {a0:  6.23, a1: 3.15, a2:  0.00, tol: 1.30}
  NVIDIA RTX A6000:                   {a0:  6.00, a1: 6.38, a2: -0.28, tol: 1.30}
  NVIDIA RTX 6000 Ada Generation:     {a0: 13.63, a1: 0.21, a2:  0.12, tol: 1.30}
  NVIDIA L40S:                        {a0:  9.58, a1: 5.61, a2: -0.35, tol: 1.30}
  NVIDIA A100-SXM4-80GB:              {a0: 31.32, a1: 1.80, a2:  0.22, tol: 1.30}
  NVIDIA H100 PCIe:                   {a0: 12.28, a1:11.48, a2: -0.60, tol: 1.30}
  NVIDIA H100 80GB HBM3:              {a0: 19.00, a1: 1.43, a2:  0.16, tol: 1.30}
  NVIDIA H200:                        {a0: 32.55, a1: 5.28, a2: -0.23, tol: 1.30}
  NVIDIA B200:                        {a0: 18.03, a1: 3.84, a2:  0.02, tol: 1.30}
  NVIDIA H100 NVL:                    {a0: 23.46, a1: 0.30, a2:  0.23, tol: 1.30}

# ─────────────────────── other runtime settings ─────────────────────────
merkle_proof:
  miner_script_path: "neurons/Validator/miner_script_m_merkletree.py"
  time_tolerance: 5
  submatrix_size: 512
  buffer_factor: 0.45
  spot_per_gpu: 3
  hash_algorithm: 'sha256'
  pog_retry_limit: 20
  pog_retry_interval: 60  # seconds
  max_workers: 64
  max_random_delay: 600 # 600 seconds

# ─────────────────────── subnet config parameters ───────────────────────
subnet_config:
  total_miner_emission: 0.05
  blocks_per_epoch: 360
  max_challenge_blocks: 11
  rand_delay_blocks_max: 5
  allow_fake_sybil_slot: true
  gpu_weights:
    NVIDIA B200:                    23
    NVIDIA H200:                    19
    NVIDIA H100 80GB HBM3:          18
    NVIDIA H100 PCIe:               16
    NVIDIA H100 NVL:                15
    NVIDIA A100-SXM4-80GB:          10
    NVIDIA A100 80GB PCIe:          9
    NVIDIA L40S:                    8
    NVIDIA L40:                     7
    NVIDIA A40:                     6
    NVIDIA GeForce RTX 5090:        5
    NVIDIA RTX 6000 Ada Generation: 4
    NVIDIA RTX A6000:               3
    NVIDIA RTX A5000:               2
    NVIDIA RTX A4500:               2
    NVIDIA RTX 4000 Ada Generation: 1
    NVIDIA GeForce RTX 4090:        1
    NVIDIA GeForce RTX 3090:        0.5
    NVIDIA L4:                      0.5

